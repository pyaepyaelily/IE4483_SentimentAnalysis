{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI9_xEfdmV6q",
        "outputId": "9d570b63-0338-4a34-82ed-dacc09674836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtSJ9Rie30oO",
        "outputId": "f280e9a2-ce2d-427d-e2e4-64aa2399ca6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGlS0uHO6qgX"
      },
      "source": [
        "# Reading in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1MvQRI47lrWb",
        "outputId": "a259ad51-b295-42ce-cb41-ca3369e37edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lJe2OeOpTgHC"
      },
      "outputs": [],
      "source": [
        "file_path_test = \"/content/drive/MyDrive/Colab Notebooks/IE4483/data/test.json\"\n",
        "\n",
        "with open(file_path_test, 'r', encoding='utf-8') as file:\n",
        "    test_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jVNz3Po-6Htt"
      },
      "outputs": [],
      "source": [
        "# 0: negative sentiment\n",
        "# 1: positive sentiment\n",
        "\n",
        "train_df = pd.DataFrame(train_data)\n",
        "test_df = pd.DataFrame(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G2lVgQ51Hki6"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtO2gpPp7DEW"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5eIvtpykAyKY"
      },
      "outputs": [],
      "source": [
        "#Lowercasing\n",
        "train_df[\"reviews\"] = train_df[\"reviews\"].astype(str).str.lower()\n",
        "train_df.head()\n",
        "\n",
        "test_df[\"reviews\"] = test_df[\"reviews\"].astype(str).str.lower()\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UNAYo_bdTNf3"
      },
      "outputs": [],
      "source": [
        "#Function to remove punctuation\n",
        "def remove_punc(text):\n",
        "    for punc in string.punctuation:\n",
        "        text = text.replace(punc, '')\n",
        "    return text\n",
        "\n",
        "\n",
        "train_df[\"reviews\"] = train_df[\"reviews\"].apply(remove_punc)\n",
        "train_df.head()\n",
        "\n",
        "test_df[\"reviews\"] = test_df[\"reviews\"].apply(remove_punc)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4R3dR6jFlIvH"
      },
      "outputs": [],
      "source": [
        "# Remove special characters and numbers from the \"reviews\" column\n",
        "train_df['reviews'] = train_df['reviews'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
        "\n",
        "test_df['reviews'] = test_df['reviews'].str.replace(r'[^A-Za-z\\s]', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HZLkH95amNso"
      },
      "outputs": [],
      "source": [
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the remove_stopwords function to the 'reviews' column\n",
        "train_df['reviews'] = train_df['reviews'].apply(remove_stopwords)\n",
        "\n",
        "test_df['reviews'] = test_df['reviews'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QNUct3kNxKvm"
      },
      "outputs": [],
      "source": [
        "findDuplicate = train_df.duplicated()\n",
        "print(findDuplicate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MFu_jaF1Etk2"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop_duplicates()\n",
        "print(train_df)\n",
        "\n",
        "test_df = test_df.drop_duplicates()\n",
        "print(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KRtBTPit6zNZ"
      },
      "outputs": [],
      "source": [
        "#Save df as csv\n",
        "train_df.to_csv('processed_train_data.csv', index=False)\n",
        "test_df.to_csv('processed_test_data.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}